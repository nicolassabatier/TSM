{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do different types of models perform on our sample data?\n",
    "\n",
    "Let's start by looking just at the first meter (Electricity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsm.evaluators import k_fold_validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/prep/train_meter_0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to exclude some features from actual modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['timestamp', 'suspicious_day', 'suspicious_month']\n",
    "y_col = ['log_meter_reading']\n",
    "x_cols = [x for x in list(data) if x not in exclude + y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default choice: **no using** suspicious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.923804\n",
       "1    0.076196\n",
       "Name: day_suspicious, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Meter 0: if suspcious_day â†’ remove\n",
    "data.day_suspicious.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.day_suspicious == False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyRegressor(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold rmsle: 1.4189585024174038\n",
      "Fold rmsle: 1.4184159343497882\n",
      "Fold rmsle: 1.4192611647343643\n",
      "Overall rmsle: 1.418878533833852\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for tr_idx, ts_idx in k_fold_validator(k=3, data=data.index.values, shuffle=True, random_state=SEED):\n",
    "    \n",
    "    x = data[x_cols].values\n",
    "    y = data[y_col].values\n",
    "    x_tr, x_ts, y_tr, y_ts = x[tr_idx], x[ts_idx], y[tr_idx], y[ts_idx]\n",
    "    \n",
    "    dummy.fit(x_tr, y_tr)\n",
    "    rmsle = sqrt(mean_squared_error(y_ts, dummy.predict(x_ts)))\n",
    "    print('Fold rmsle:', rmsle)\n",
    "    errors.append(rmsle)\n",
    "\n",
    "print('Overall rmsle:', sum(errors) / len(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg = RandomForestRegressor(n_estimators=7, max_depth=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold rmsle: 0.6144330476351351\n",
      "Fold rmsle: 0.6134558442236404\n",
      "Fold rmsle: 0.6153539690786224\n",
      "Overall rmsle: 0.6144142869791326\n",
      "CPU times: user 2h 2min 28s, sys: 10.2 s, total: 2h 2min 38s\n",
      "Wall time: 18min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "errors = []\n",
    "for tr_idx, ts_idx in k_fold_validator(k=3, data=data.index.values, shuffle=True, random_state=SEED):\n",
    "    \n",
    "    x = data[x_cols].values\n",
    "    y = data[y_col].values\n",
    "    x_tr, x_ts, y_tr, y_ts = x[tr_idx], x[ts_idx], y[tr_idx], y[ts_idx]\n",
    "    \n",
    "    rfreg.fit(x_tr, y_tr.ravel())\n",
    "    rmsle = sqrt(mean_squared_error(y_ts, rfreg.predict(x_ts)))\n",
    "    print('Fold rmsle:', rmsle)\n",
    "    errors.append(rmsle)\n",
    "\n",
    "print('Overall rmsle:', sum(errors) / len(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_reg_params = {'objective':'regression',  'boosting_type':'gbdt', 'metric':'rmse',\n",
    "                  'n_jobs':-1, 'learning_rate':0.07, 'num_leaves': 2**8, 'max_depth':-1,\n",
    "                  'tree_learner':'serial', 'colsample_bytree': 0.7, 'subsample_freq':1,\n",
    "                  'subsample':0.5, 'max_bin': 255, 'verbose':1, 'seed': SEED,\n",
    "                 'device': 'gpu'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "LightGBMError",
     "evalue": "GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   1664\u001b[0m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1666\u001b[0;31m                 ctypes.byref(self.handle)))\n\u001b[0m\u001b[1;32m   1667\u001b[0m             \u001b[0;31m# save reference to data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \"\"\"\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "errors = []\n",
    "for tr_idx, ts_idx in k_fold_validator(k=3, data=data.index.values, shuffle=True, random_state=42):\n",
    "    \n",
    "    x = data[x_cols].values\n",
    "    y = data[y_col].values\n",
    "    x_tr, x_ts, y_tr, y_ts = x[tr_idx], x[ts_idx], y[tr_idx], y[ts_idx]\n",
    "    \n",
    "    \n",
    "    lgb_train = lgb.Dataset(x_tr, y_tr.ravel())\n",
    "    lgb_eval = lgb.Dataset(x_ts, y_ts.ravel())\n",
    "    lgb_reg = lgb.train(lgb_reg_params, lgb_train, valid_sets=(lgb_train, lgb_eval),num_boost_round=1000,early_stopping_rounds=100,verbose_eval=10)\n",
    "    rmsle = sqrt(mean_squared_error(y_ts, lgb_reg.predict(x_ts, num_iteration=lgb_reg.best_iteration)))\n",
    "    print('Fold rmsle:', rmsle)\n",
    "    errors.append(rmsle)\n",
    "\n",
    "print('Overall rmsle:', sum(errors) / len(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lgb_reg, 'objects/lgb_reg_met0_rmsle_{}.pkl'.format(sum(errors) / len(errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:23:03] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
      "[0]\teval-rmse:3.50534\ttrain-rmse:3.50419\n",
      "Multiple eval metrics have been passed: 'train-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until train-rmse hasn't improved in 10 rounds.\n",
      "[1]\teval-rmse:3.17519\ttrain-rmse:3.17394\n",
      "[2]\teval-rmse:2.88094\ttrain-rmse:2.87974\n",
      "[3]\teval-rmse:2.61653\ttrain-rmse:2.61559\n",
      "[4]\teval-rmse:2.3811\ttrain-rmse:2.38012\n",
      "[5]\teval-rmse:2.17181\ttrain-rmse:2.17077\n",
      "[6]\teval-rmse:1.98368\ttrain-rmse:1.98284\n",
      "[7]\teval-rmse:1.81761\ttrain-rmse:1.81672\n",
      "[8]\teval-rmse:1.66999\ttrain-rmse:1.66908\n",
      "[9]\teval-rmse:1.53877\ttrain-rmse:1.53789\n",
      "Fold rmsle: 1.5388655173404837\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "errors = []\n",
    "for tr_idx, ts_idx in k_fold_validator(k=3, data=data.index.values, shuffle=True, random_state=SEED):\n",
    "    \n",
    "    x = data[x_cols].values\n",
    "    y = data[y_col].values\n",
    "    x_tr, x_ts, y_tr, y_ts = x[tr_idx], x[ts_idx], y[tr_idx], y[ts_idx]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(x_tr, label=y_tr)\n",
    "    dtest = xgb.DMatrix(x_ts, label=y_ts)\n",
    "    num_round = 10\n",
    "    param = {}\n",
    "    param = {'max_depth': 10, 'eta': 0.1, 'objective': 'reg:squarederror', 'eval_metric': 'rmse'}\n",
    "    evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "    bst = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds=10)\n",
    "    \n",
    "    rmsle = sqrt(mean_squared_error(y_ts, bst.predict(dtest, ntree_limit=bst.best_ntree_limit)))\n",
    "    print('Fold rmsle:', rmsle)\n",
    "    errors.append(rmsle)\n",
    "\n",
    "print('Overall rmsle:', sum(errors) / len(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
