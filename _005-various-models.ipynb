{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do different types of models perform on our sample data?\n",
    "\n",
    "Let's start by looking just at the first meter (Electricity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsm.evaluators import k_fold_validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/prep/train_meter_0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to exclude some features from actual modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['timestamp', 'suspicious_day', 'suspicious_month']\n",
    "y_col = ['log_meter_reading']\n",
    "x_cols = [x for x in list(data) if x not in exclude + y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default choice: **no using** suspicious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.923804\n",
       "1    0.076196\n",
       "Name: day_suspicious, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Meter 0: if suspcious_day â†’ remove\n",
    "data.day_suspicious.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.day_suspicious == False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyRegressor(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold rmsle: 1.4189585024174038\n",
      "Fold rmsle: 1.4184159343497882\n",
      "Fold rmsle: 1.4192611647343643\n",
      "Overall rmsle: 1.418878533833852\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for tr_idx, ts_idx in k_fold_validator(k=3, data=data.index.values, shuffle=True, random_state=SEED):\n",
    "    \n",
    "    x = data[x_cols].values\n",
    "    y = data[y_col].values\n",
    "    x_tr, x_ts, y_tr, y_ts = x[tr_idx], x[ts_idx], y[tr_idx], y[ts_idx]\n",
    "    \n",
    "    dummy.fit(x_tr, y_tr)\n",
    "    rmsle = sqrt(mean_squared_error(y_ts, dummy.predict(x_ts)))\n",
    "    print('Fold rmsle:', rmsle)\n",
    "    errors.append(rmsle)\n",
    "\n",
    "print('Overall rmsle:', sum(errors) / len(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg = RandomForestRegressor(n_estimators=7, max_depth=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold rmsle: 0.6144330476351351\n",
      "Fold rmsle: 0.6134558442236404\n",
      "Fold rmsle: 0.6153539690786224\n",
      "Overall rmsle: 0.6144142869791326\n",
      "CPU times: user 2h 2min 28s, sys: 10.2 s, total: 2h 2min 38s\n",
      "Wall time: 18min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "errors = []\n",
    "for tr_idx, ts_idx in k_fold_validator(k=3, data=data.index.values, shuffle=True, random_state=SEED):\n",
    "    \n",
    "    x = data[x_cols].values\n",
    "    y = data[y_col].values\n",
    "    x_tr, x_ts, y_tr, y_ts = x[tr_idx], x[ts_idx], y[tr_idx], y[ts_idx]\n",
    "    \n",
    "    rfreg.fit(x_tr, y_tr.ravel())\n",
    "    rmsle = sqrt(mean_squared_error(y_ts, rfreg.predict(x_ts)))\n",
    "    print('Fold rmsle:', rmsle)\n",
    "    errors.append(rmsle)\n",
    "\n",
    "print('Overall rmsle:', sum(errors) / len(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_reg_params = {'objective':'regression',  'boosting_type':'gbdt', 'metric':'rmse',\n",
    "                  'n_jobs':-1, 'learning_rate':0.07, 'num_leaves': 2**8, 'max_depth':-1,\n",
    "                  'tree_learner':'serial', 'colsample_bytree': 0.7, 'subsample_freq':1,\n",
    "                  'subsample':0.5, 'max_bin': 255, 'verbose':1, 'seed': SEED}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\ttraining's rmse: 1.12948\tvalid_1's rmse: 1.13001\n",
      "[20]\ttraining's rmse: 0.81353\tvalid_1's rmse: 0.814139\n",
      "[30]\ttraining's rmse: 0.689982\tvalid_1's rmse: 0.690583\n",
      "[40]\ttraining's rmse: 0.606731\tvalid_1's rmse: 0.607398\n",
      "[50]\ttraining's rmse: 0.557475\tvalid_1's rmse: 0.558293\n",
      "[60]\ttraining's rmse: 0.522376\tvalid_1's rmse: 0.523213\n",
      "[70]\ttraining's rmse: 0.49405\tvalid_1's rmse: 0.495039\n",
      "[80]\ttraining's rmse: 0.473465\tvalid_1's rmse: 0.474588\n",
      "[90]\ttraining's rmse: 0.451841\tvalid_1's rmse: 0.453155\n",
      "[100]\ttraining's rmse: 0.436818\tvalid_1's rmse: 0.438296\n",
      "[110]\ttraining's rmse: 0.424357\tvalid_1's rmse: 0.426011\n",
      "[120]\ttraining's rmse: 0.413872\tvalid_1's rmse: 0.415652\n",
      "[130]\ttraining's rmse: 0.404167\tvalid_1's rmse: 0.406205\n",
      "[140]\ttraining's rmse: 0.395855\tvalid_1's rmse: 0.39796\n",
      "[150]\ttraining's rmse: 0.388486\tvalid_1's rmse: 0.390745\n",
      "[160]\ttraining's rmse: 0.381966\tvalid_1's rmse: 0.384341\n",
      "[170]\ttraining's rmse: 0.375417\tvalid_1's rmse: 0.377856\n",
      "[180]\ttraining's rmse: 0.368572\tvalid_1's rmse: 0.37111\n",
      "[190]\ttraining's rmse: 0.364052\tvalid_1's rmse: 0.366688\n",
      "[200]\ttraining's rmse: 0.35902\tvalid_1's rmse: 0.361762\n",
      "[210]\ttraining's rmse: 0.353905\tvalid_1's rmse: 0.356708\n",
      "[220]\ttraining's rmse: 0.349975\tvalid_1's rmse: 0.352884\n",
      "[230]\ttraining's rmse: 0.346721\tvalid_1's rmse: 0.349701\n",
      "[240]\ttraining's rmse: 0.343171\tvalid_1's rmse: 0.346315\n",
      "[250]\ttraining's rmse: 0.339703\tvalid_1's rmse: 0.342951\n",
      "[260]\ttraining's rmse: 0.336568\tvalid_1's rmse: 0.339937\n",
      "[270]\ttraining's rmse: 0.333697\tvalid_1's rmse: 0.337201\n",
      "[280]\ttraining's rmse: 0.330725\tvalid_1's rmse: 0.334342\n",
      "[290]\ttraining's rmse: 0.328619\tvalid_1's rmse: 0.332321\n",
      "[300]\ttraining's rmse: 0.326052\tvalid_1's rmse: 0.329853\n",
      "[310]\ttraining's rmse: 0.323935\tvalid_1's rmse: 0.327832\n",
      "[320]\ttraining's rmse: 0.321313\tvalid_1's rmse: 0.325318\n",
      "[330]\ttraining's rmse: 0.31888\tvalid_1's rmse: 0.323022\n",
      "[340]\ttraining's rmse: 0.316591\tvalid_1's rmse: 0.320828\n",
      "[350]\ttraining's rmse: 0.314967\tvalid_1's rmse: 0.319302\n",
      "[360]\ttraining's rmse: 0.312887\tvalid_1's rmse: 0.317303\n",
      "[370]\ttraining's rmse: 0.310793\tvalid_1's rmse: 0.315297\n",
      "[380]\ttraining's rmse: 0.308172\tvalid_1's rmse: 0.31274\n",
      "[390]\ttraining's rmse: 0.306427\tvalid_1's rmse: 0.311096\n",
      "[400]\ttraining's rmse: 0.304832\tvalid_1's rmse: 0.309575\n",
      "[410]\ttraining's rmse: 0.30257\tvalid_1's rmse: 0.307384\n",
      "[420]\ttraining's rmse: 0.300612\tvalid_1's rmse: 0.305544\n",
      "[430]\ttraining's rmse: 0.298993\tvalid_1's rmse: 0.304015\n",
      "[440]\ttraining's rmse: 0.297193\tvalid_1's rmse: 0.302297\n",
      "[450]\ttraining's rmse: 0.295371\tvalid_1's rmse: 0.300566\n",
      "[460]\ttraining's rmse: 0.293696\tvalid_1's rmse: 0.298958\n",
      "[470]\ttraining's rmse: 0.292144\tvalid_1's rmse: 0.297511\n",
      "[480]\ttraining's rmse: 0.290978\tvalid_1's rmse: 0.296408\n",
      "[490]\ttraining's rmse: 0.289734\tvalid_1's rmse: 0.295256\n",
      "[500]\ttraining's rmse: 0.288373\tvalid_1's rmse: 0.293978\n",
      "[510]\ttraining's rmse: 0.286631\tvalid_1's rmse: 0.292332\n",
      "[520]\ttraining's rmse: 0.285244\tvalid_1's rmse: 0.291023\n",
      "[530]\ttraining's rmse: 0.283849\tvalid_1's rmse: 0.289698\n",
      "[540]\ttraining's rmse: 0.282782\tvalid_1's rmse: 0.288716\n",
      "[550]\ttraining's rmse: 0.281415\tvalid_1's rmse: 0.287423\n",
      "[560]\ttraining's rmse: 0.280353\tvalid_1's rmse: 0.286432\n",
      "[570]\ttraining's rmse: 0.279264\tvalid_1's rmse: 0.285412\n",
      "[580]\ttraining's rmse: 0.278393\tvalid_1's rmse: 0.284622\n",
      "[590]\ttraining's rmse: 0.277162\tvalid_1's rmse: 0.283481\n",
      "[600]\ttraining's rmse: 0.275937\tvalid_1's rmse: 0.28234\n",
      "[610]\ttraining's rmse: 0.274727\tvalid_1's rmse: 0.28121\n",
      "[620]\ttraining's rmse: 0.273675\tvalid_1's rmse: 0.280224\n",
      "[630]\ttraining's rmse: 0.272851\tvalid_1's rmse: 0.279481\n",
      "[640]\ttraining's rmse: 0.271637\tvalid_1's rmse: 0.278363\n",
      "[650]\ttraining's rmse: 0.270851\tvalid_1's rmse: 0.27765\n",
      "[660]\ttraining's rmse: 0.26982\tvalid_1's rmse: 0.276702\n",
      "[670]\ttraining's rmse: 0.268948\tvalid_1's rmse: 0.275914\n",
      "[680]\ttraining's rmse: 0.268226\tvalid_1's rmse: 0.275265\n",
      "[690]\ttraining's rmse: 0.267181\tvalid_1's rmse: 0.274287\n",
      "[700]\ttraining's rmse: 0.266359\tvalid_1's rmse: 0.273551\n",
      "[710]\ttraining's rmse: 0.265388\tvalid_1's rmse: 0.272657\n",
      "[720]\ttraining's rmse: 0.264612\tvalid_1's rmse: 0.271949\n",
      "[730]\ttraining's rmse: 0.26364\tvalid_1's rmse: 0.271032\n",
      "[740]\ttraining's rmse: 0.262675\tvalid_1's rmse: 0.270135\n",
      "[750]\ttraining's rmse: 0.261745\tvalid_1's rmse: 0.269287\n",
      "[760]\ttraining's rmse: 0.261179\tvalid_1's rmse: 0.268796\n",
      "[770]\ttraining's rmse: 0.260589\tvalid_1's rmse: 0.268277\n",
      "[780]\ttraining's rmse: 0.259609\tvalid_1's rmse: 0.267358\n",
      "[790]\ttraining's rmse: 0.258883\tvalid_1's rmse: 0.266703\n",
      "[800]\ttraining's rmse: 0.258106\tvalid_1's rmse: 0.265988\n",
      "[810]\ttraining's rmse: 0.257317\tvalid_1's rmse: 0.265284\n",
      "[820]\ttraining's rmse: 0.256571\tvalid_1's rmse: 0.264613\n",
      "[830]\ttraining's rmse: 0.255757\tvalid_1's rmse: 0.263869\n",
      "[840]\ttraining's rmse: 0.254997\tvalid_1's rmse: 0.263184\n",
      "[850]\ttraining's rmse: 0.254244\tvalid_1's rmse: 0.262495\n",
      "[860]\ttraining's rmse: 0.253635\tvalid_1's rmse: 0.261968\n",
      "[870]\ttraining's rmse: 0.252937\tvalid_1's rmse: 0.261325\n",
      "[880]\ttraining's rmse: 0.252423\tvalid_1's rmse: 0.260863\n",
      "[890]\ttraining's rmse: 0.251592\tvalid_1's rmse: 0.260098\n",
      "[900]\ttraining's rmse: 0.25095\tvalid_1's rmse: 0.259515\n",
      "[910]\ttraining's rmse: 0.250318\tvalid_1's rmse: 0.258954\n",
      "[920]\ttraining's rmse: 0.249649\tvalid_1's rmse: 0.258339\n",
      "[930]\ttraining's rmse: 0.249104\tvalid_1's rmse: 0.257856\n",
      "[940]\ttraining's rmse: 0.248655\tvalid_1's rmse: 0.257469\n",
      "[950]\ttraining's rmse: 0.248209\tvalid_1's rmse: 0.257088\n",
      "[960]\ttraining's rmse: 0.247671\tvalid_1's rmse: 0.256619\n",
      "[970]\ttraining's rmse: 0.247039\tvalid_1's rmse: 0.256033\n",
      "[980]\ttraining's rmse: 0.24632\tvalid_1's rmse: 0.25538\n",
      "[990]\ttraining's rmse: 0.245752\tvalid_1's rmse: 0.254871\n",
      "[1000]\ttraining's rmse: 0.245224\tvalid_1's rmse: 0.254405\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.245224\tvalid_1's rmse: 0.254405\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "errors = []\n",
    "for tr_idx, ts_idx in k_fold_validator(k=3, data=data.index.values, shuffle=True, random_state=42):\n",
    "    \n",
    "    x = data[x_cols].values\n",
    "    y = data[y_col].values\n",
    "    x_tr, x_ts, y_tr, y_ts = x[tr_idx], x[ts_idx], y[tr_idx], y[ts_idx]\n",
    "    \n",
    "    \n",
    "    lgb_train = lgb.Dataset(x_tr, y_tr.ravel())\n",
    "    lgb_eval = lgb.Dataset(x_ts, y_ts.ravel())\n",
    "    lgb_reg = lgb.train(lgb_reg_params, lgb_train, valid_sets=(lgb_train, lgb_eval),num_boost_round=1000,early_stopping_rounds=100,verbose_eval=10)\n",
    "    rmsle = sqrt(mean_squared_error(y_ts, lgb_reg.predict(x_ts, num_iteration=lgb_reg.best_iteration)))\n",
    "    print('Fold rmsle:', rmsle)\n",
    "    errors.append(rmsle)\n",
    "\n",
    "print('Overall rmsle:', sum(errors) / len(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lgb_reg, 'objects/lgb_reg_met0_rmsle_{}.pkl'.format(sum(errors) / len(errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:23:03] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
      "[0]\teval-rmse:3.50534\ttrain-rmse:3.50419\n",
      "Multiple eval metrics have been passed: 'train-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until train-rmse hasn't improved in 10 rounds.\n",
      "[1]\teval-rmse:3.17519\ttrain-rmse:3.17394\n",
      "[2]\teval-rmse:2.88094\ttrain-rmse:2.87974\n",
      "[3]\teval-rmse:2.61653\ttrain-rmse:2.61559\n",
      "[4]\teval-rmse:2.3811\ttrain-rmse:2.38012\n",
      "[5]\teval-rmse:2.17181\ttrain-rmse:2.17077\n",
      "[6]\teval-rmse:1.98368\ttrain-rmse:1.98284\n",
      "[7]\teval-rmse:1.81761\ttrain-rmse:1.81672\n",
      "[8]\teval-rmse:1.66999\ttrain-rmse:1.66908\n",
      "[9]\teval-rmse:1.53877\ttrain-rmse:1.53789\n",
      "Fold rmsle: 1.5388655173404837\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "errors = []\n",
    "for tr_idx, ts_idx in k_fold_validator(k=3, data=data.index.values, shuffle=True, random_state=SEED):\n",
    "    \n",
    "    x = data[x_cols].values\n",
    "    y = data[y_col].values\n",
    "    x_tr, x_ts, y_tr, y_ts = x[tr_idx], x[ts_idx], y[tr_idx], y[ts_idx]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(x_tr, label=y_tr)\n",
    "    dtest = xgb.DMatrix(x_ts, label=y_ts)\n",
    "    num_round = 10\n",
    "    param = {}\n",
    "    param = {'max_depth': 10, 'eta': 0.1, 'objective': 'reg:squarederror', 'eval_metric': 'rmse'}\n",
    "    evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "    bst = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds=10)\n",
    "    \n",
    "    rmsle = sqrt(mean_squared_error(y_ts, bst.predict(dtest, ntree_limit=bst.best_ntree_limit)))\n",
    "    print('Fold rmsle:', rmsle)\n",
    "    errors.append(rmsle)\n",
    "\n",
    "print('Overall rmsle:', sum(errors) / len(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
