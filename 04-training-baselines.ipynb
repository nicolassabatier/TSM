{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meter 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "met0_tr = pd.read_pickle('kaggle/prepo_train_met0.pkl')\n",
    "met0_vl = pd.read_pickle('kaggle/prepo_val_met0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10661397, 1399513)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(met0_tr), len(met0_vl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute mean meter reading by building by month on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsm.data_utils import compute_and_add_mean_by_a_and_b, only_add_mean_by_a_and_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdd46e8556c494dbef759e252290617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10661397), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6e4b8d8e36b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmet0_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_means_by_bid_and_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_and_add_mean_by_a_and_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmet0_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'meter_reading'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'building_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dt_m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/TSM/tsm/data_utils.py\u001b[0m in \u001b[0;36mcompute_and_add_mean_by_a_and_b\u001b[0;34m(df, mean_of, a, b)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mx_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_by\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmean_by\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_of\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mmeans_by_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mdf_with_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monly_add_mean_by_a_and_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_of\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans_by_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_with_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans_by_a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TSM/tsm/data_utils.py\u001b[0m in \u001b[0;36monly_add_mean_by_a_and_b\u001b[0;34m(df, mean_of, a, b, means_by_a_and_b)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0monly_add_mean_by_a_and_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_of\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans_by_a_and_b\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     means_by_and_b_df = pd.DataFrame(df[a].progress_apply(lambda x: [x[mean_of] for x in means_by_a_and_b[x]]).values.tolist(),\n\u001b[0m\u001b[1;32m    141\u001b[0m         columns=['{}_{}_{}_mean'.format(a, b, y) for y in [y[b] for y in means_by_a_and_b[df[a].values[0]]]]).reset_index(drop=True)\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans_by_and_b_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m                 \u001b[0;31m# Close bar and return pandas calculation result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4040\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4041\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4042\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4044\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    729\u001b[0m                     \u001b[0;31m# on the first column/row to decide whether it can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;31m# cannot catch KeyboardInterrupt when using manual tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "met0_tr, tr_means_by_bid_and_m = compute_and_add_mean_by_a_and_b(met0_tr, mean_of='meter_reading', a='building_id', b='dt_m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36883b171a24c35b7ff20aaecc458bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1399513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "met0_vl = only_add_mean_by_a_and_b(met0_vl, mean_of='meter_reading', a='building_id', b='dt_m', means_by_a_and_b=tr_means_by_bid_and_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-compress memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsm.data_utils import compress_memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "met0_tr = met0_tr.drop('timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52565d964ba04f12a7b716b14497f839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='DataFrame: compress_memory_usage', max=58, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "met0_tr, _ = compress_memory_usage(met0_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "met0_vl = met0_vl.drop('timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3b422f5f8142f1b0fcfddef0e2b888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='DataFrame: compress_memory_usage', max=58, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "met0_vl, _ = compress_memory_usage(met0_vl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save as pickle to save time later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "met0_tr.to_pickle('kaggle/prepo_train_met0_bIDbyM_means.pkl')\n",
    "met0_vl.to_pickle('kaggle/prepo_val_met0__bIDbyM_means.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kaggle/prepo_train_met0_tr_means_by_bid_and_m.pkl', 'wb') as f_out:\n",
    "    pickle.dump(tr_means_by_bid_and_m, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reloading: restart from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "met0_tr = pd.read_pickle('kaggle/prepo_train_met0_bIDbyM_means.pkl')\n",
    "met0_vl = pd.read_pickle('kaggle/prepo_val_met0__bIDbyM_means.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kaggle/prepo_train_met0_tr_means_by_bid_and_m.pkl', 'rb') as f_in:\n",
    "    mt0_tr_means_by_bid_and_m = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1) LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsm.eval_metrics import root_mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_reg_params = {'objective':'regression',  'boosting_type':'gbdt', 'metric':'rmse',\n",
    "                  'n_jobs':-1, 'learning_rate':0.07, 'num_leaves': 2**8, 'max_depth':-1,\n",
    "                  'tree_learner':'serial', 'colsample_bytree': 0.7, 'subsample_freq':1,\n",
    "                  'subsample':0.5, 'max_bin':255, 'verbose':1, 'seed': SEED, 'early_stopping_rounds': 40}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [x for x in list(met0_tr) if x not in ['timestamp', 'meter_reading']]\n",
    "y = 'meter_reading'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "met0_tr_x = met0_tr[xs]\n",
    "met0_tr_y = met0_tr[y]\n",
    "met0_vl_x = met0_vl[xs]\n",
    "met0_vl_y = met0_vl[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                          Type              Data/Info\n",
      "-------------------------------------------------------------\n",
      "SEED                              int               0\n",
      "compute_and_add_mean_by_a_and_b   function          <function compute_and_add<...>_and_b at 0x7fb1a7f5bb70>\n",
      "f_in                              BufferedReader    <_io.BufferedReader name=<...>_means_by_bid_and_m.pkl'>\n",
      "f_out                             BufferedWriter    <_io.BufferedWriter name=<...>_means_by_bid_and_m.pkl'>\n",
      "lgb                               module            <module 'lightgbm' from '<...>es/lightgbm/__init__.py'>\n",
      "lgb_eval                          Dataset           <lightgbm.basic.Dataset object at 0x7fb16150ff60>\n",
      "lgb_reg_params                    dict              n=15\n",
      "lgb_train                         Dataset           <lightgbm.basic.Dataset object at 0x7fb16150f358>\n",
      "met0_tr                           DataFrame                   building_id    <...>661397 rows x 59 columns]\n",
      "met0_tr_x                         DataFrame                   building_id  si<...>661397 rows x 57 columns]\n",
      "met0_tr_y                         Series            0             0.000000\\n1<...> 10661397, dtype: float32\n",
      "met0_vl                           DataFrame                  building_id     <...>399513 rows x 59 columns]\n",
      "met0_vl_x                         DataFrame                  building_id  sit<...>399513 rows x 57 columns]\n",
      "met0_vl_y                         Series            0            0.000\\n1    <...>: 1399513, dtype: float32\n",
      "only_add_mean_by_a_and_b          function          <function only_add_mean_b<...>_and_b at 0x7fb1a7f5bbf8>\n",
      "pd                                module            <module 'pandas' from '/u<...>ages/pandas/__init__.py'>\n",
      "pickle                            module            <module 'pickle' from '/u<...>lib/python3.5/pickle.py'>\n",
      "root_mean_squared_log_error       function          <function root_mean_squar<...>_error at 0x7fb1d8d838c8>\n",
      "tr_means_by_bid_and_m             dict              n=1413\n",
      "x_cols                            list              n=57\n",
      "xs                                list              n=57\n",
      "y                                 str               meter_reading\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "del met0_tr, met0_vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Ric/.local/lib/python3.5/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 40 rounds\n",
      "[20]\ttraining's rmse: 119.759\tvalid_1's rmse: 124.142\n",
      "[40]\ttraining's rmse: 77.0525\tvalid_1's rmse: 85.5459\n",
      "[60]\ttraining's rmse: 69.6232\tvalid_1's rmse: 80.7385\n",
      "[80]\ttraining's rmse: 66.164\tvalid_1's rmse: 79.7223\n",
      "[100]\ttraining's rmse: 63.8183\tvalid_1's rmse: 78.8084\n",
      "[120]\ttraining's rmse: 61.7802\tvalid_1's rmse: 78.0157\n",
      "[140]\ttraining's rmse: 60.345\tvalid_1's rmse: 77.5614\n",
      "[160]\ttraining's rmse: 59.1499\tvalid_1's rmse: 77.4934\n",
      "[180]\ttraining's rmse: 58.2036\tvalid_1's rmse: 77.2936\n",
      "[200]\ttraining's rmse: 57.2973\tvalid_1's rmse: 77.3272\n",
      "[220]\ttraining's rmse: 56.3738\tvalid_1's rmse: 76.9794\n",
      "[240]\ttraining's rmse: 55.68\tvalid_1's rmse: 76.9387\n",
      "[260]\ttraining's rmse: 54.8786\tvalid_1's rmse: 76.9175\n",
      "[280]\ttraining's rmse: 54.2309\tvalid_1's rmse: 76.9433\n",
      "Early stopping, best iteration is:\n",
      "[252]\ttraining's rmse: 55.2124\tvalid_1's rmse: 76.767\n"
     ]
    }
   ],
   "source": [
    "mt0_lgb_train = lgb.Dataset(met0_tr_x, met0_tr_y)\n",
    "mt0_lgb_eval = lgb.Dataset(met0_vl_x, met0_vl_y)\n",
    "mt0_gbm_regress = lgb.train(lgb_reg_params, mt0_lgb_train, num_boost_round=2000, valid_sets=(mt0_lgb_train, mt0_lgb_eval),verbose_eval = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Ric/TSM/tsm/eval_metrics.py:5: RuntimeWarning: invalid value encountered in log\n",
      "  return np.sqrt(np.sum(np.power(np.log(predicted + 1) - np.log(actual + 1), 2)) / len(actual))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NRMLSE: 0.6020488382795164\n",
      "Validation NRMLSE: 0.6820828571711314\n"
     ]
    }
   ],
   "source": [
    "lgbm_tr_hat = (gbm_regress.predict(met0_tr_x, num_iteration=gbm_regress.best_iteration))\n",
    "print('Training NRMLSE:', root_mean_squared_log_error(lgbm_tr_hat, met0_tr_y))\n",
    "\n",
    "lgbm_vl_hat = (gbm_regress.predict(met0_vl_x, num_iteration=gbm_regress.best_iteration))\n",
    "print('Validation NRMLSE:', root_mean_squared_log_error(lgbm_vl_hat, met0_vl_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Ric/.local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/mt0_gbm_regress.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mt0_gbm_regress, 'models/mt0_gbm_regress.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "met1_tr = pd.read_pickle('kaggle/prepo_train_met1.pkl')\n",
    "met1_vl = pd.read_pickle('kaggle/prepo_val_met1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_and_add_mean_by_a_and_b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1690a7f62d34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmet1_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmt_1tr_means_by_bid_and_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_and_add_mean_by_a_and_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmet1_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'meter_reading'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'building_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dt_m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_and_add_mean_by_a_and_b' is not defined"
     ]
    }
   ],
   "source": [
    "met1_tr, mt_1tr_means_by_bid_and_m = compute_and_add_mean_by_a_and_b(met1_tr, mean_of='meter_reading', a='building_id', b='dt_m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=480005), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "met1_vl = only_add_mean_by_a_and_b(met1_vl, mean_of='meter_reading', a='building_id', b='dt_m', means_by_a_and_b=mt_1tr_means_by_bid_and_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "met1_tr = met1_tr.drop('timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='DataFrame: compress_memory_usage', max=58, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage pre-compression was 1200.5119590759277\n",
      "Memory usage after-compression was 677.9362182617188\n",
      "This is  56.470592661446524% of the initial size\n"
     ]
    }
   ],
   "source": [
    "met1_tr, _ = compress_memory_usage(met1_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "met1_vl = met1_vl.drop('timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='DataFrame: compress_memory_usage', max=58, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage pre-compression was 155.6413917541504\n",
      "Memory usage after-compression was 87.89166259765625\n",
      "This is  56.470622375626824% of the initial size\n"
     ]
    }
   ],
   "source": [
    "met1_vl, _ = compress_memory_usage(met1_vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "met1_tr.to_pickle('kaggle/prepo_train_met1_bIDbyM_means.pkl')\n",
    "met1_vl.to_pickle('kaggle/prepo_val_met1_bIDbyM_means.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kaggle/prepo_train_met1_tr_means_by_bid_and_m.pkl', 'wb') as f_out:\n",
    "    pickle.dump(mt_1tr_means_by_bid_and_m, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "met1_tr = pd.read_pickle('kaggle/prepo_train_met1_bIDbyM_means.pkl')\n",
    "met1_vl = pd.read_pickle ('kaggle/prepo_val_met1_bIDbyM_means.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [x for x in list(met1_tr) if x not in ['timestamp', 'meter_reading']]\n",
    "y = 'meter_reading'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "met1_tr_x = met1_tr[xs]\n",
    "met1_tr_y = met1_tr[y]\n",
    "met1_vl_x = met1_vl[xs]\n",
    "met1_vl_y = met1_vl[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Ric/.local/lib/python3.5/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 40 rounds\n",
      "[20]\ttraining's rmse: 2511.44\tvalid_1's rmse: 4669.04\n",
      "[40]\ttraining's rmse: 1472.94\tvalid_1's rmse: 3795.93\n",
      "[60]\ttraining's rmse: 1226.38\tvalid_1's rmse: 3689.2\n",
      "[80]\ttraining's rmse: 1090.02\tvalid_1's rmse: 3646.62\n",
      "[100]\ttraining's rmse: 1001.56\tvalid_1's rmse: 3636.51\n",
      "[120]\ttraining's rmse: 924.744\tvalid_1's rmse: 3633.53\n",
      "[140]\ttraining's rmse: 870.341\tvalid_1's rmse: 3650.83\n",
      "Early stopping, best iteration is:\n",
      "[105]\ttraining's rmse: 980.043\tvalid_1's rmse: 3619.91\n"
     ]
    }
   ],
   "source": [
    "mt1_lgb_train = lgb.Dataset(met1_tr_x, met1_tr_y)\n",
    "mt1_lgb_eval = lgb.Dataset(met1_vl_x, met1_vl_y)\n",
    "mt1_gbm_regress = lgb.train(lgb_reg_params, mt1_lgb_train, num_boost_round=2000, valid_sets=(mt1_lgb_train, mt1_lgb_eval),verbose_eval = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Ric/TSM/tsm/eval_metrics.py:5: RuntimeWarning: invalid value encountered in log\n",
      "  return np.sqrt(np.sum(np.power(np.log(predicted + 1) - np.log(actual + 1), 2)) / len(actual))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NRMLSE: 1.5414553172411622\n",
      "Validation NRMLSE: 1.7537242860741826\n"
     ]
    }
   ],
   "source": [
    "lgbm_tr_hat = (gbm_regress.predict(met1_tr_x, num_iteration=gbm_regress.best_iteration))\n",
    "print('Training NRMLSE:', root_mean_squared_log_error(lgbm_tr_hat, met1_tr_y))\n",
    "\n",
    "lgbm_vl_hat = (gbm_regress.predict(met1_vl_x, num_iteration=gbm_regress.best_iteration))\n",
    "print('Validation NRMLSE:', root_mean_squared_log_error(lgbm_vl_hat, met1_vl_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/mt1_gbm_regress.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mt1_gbm_regress, 'models/mt1_gbm_regress.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                      Type              Data/Info\n",
      "---------------------------------------------------------\n",
      "SEED                          int               0\n",
      "f_in                          BufferedReader    <_io.BufferedReader name=<...>_means_by_bid_and_m.pkl'>\n",
      "joblib                        module            <module 'sklearn.external<...>nals/joblib/__init__.py'>\n",
      "lgb                           module            <module 'lightgbm' from '<...>es/lightgbm/__init__.py'>\n",
      "lgb_reg_params                dict              n=15\n",
      "pd                            module            <module 'pandas' from '/u<...>ages/pandas/__init__.py'>\n",
      "pickle                        module            <module 'pickle' from '/u<...>lib/python3.5/pickle.py'>\n",
      "root_mean_squared_log_error   function          <function root_mean_squar<...>_error at 0x7fd0382beb70>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mt0_tr_means_by_bid_and_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lgb_train, lgb_eval, lgbm_tr_hat, lgbm_vl_hat, met1_tr, met1_tr_x, met1_tr_y, met1_vl, met1_vl_x, met1_vl_y, mt_1tr_means_by_bid_and_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del met1_tr, met1_vl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "met2_tr = pd.read_pickle('kaggle/prepo_train_met2.pkl')\n",
    "met2_vl = pd.read_pickle('kaggle/prepo_val_met2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2387956), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "met2_tr, mt_2tr_means_by_bid_and_m = compute_and_add_mean_by_a_and_b(met2_tr, mean_of='meter_reading', a='building_id', b='dt_m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=320757), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "met2_vl = only_add_mean_by_a_and_b(met2_vl, mean_of='meter_reading', a='building_id', b='dt_m', means_by_a_and_b=mt_2tr_means_by_bid_and_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "met2_tr = met2_tr.drop('timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='DataFrame: compress_memory_usage', max=58, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage pre-compression was 774.2931060791016\n",
      "Memory usage after-compression was 437.2479248046875\n",
      "This is  56.47059509787478% of the initial size\n"
     ]
    }
   ],
   "source": [
    "met2_tr, _ = compress_memory_usage(met2_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "met2_vl = met2_vl.drop('timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='DataFrame: compress_memory_usage', max=58, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage pre-compression was 104.00534439086914\n",
      "Memory usage after-compression was 58.73248291015625\n",
      "This is  56.470639325446534% of the initial size\n"
     ]
    }
   ],
   "source": [
    "met2_vl, _ = compress_memory_usage(met2_vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "met2_tr = pd.read_pickle('kaggle/prepo_train_met2_bIDbyM_means.pkl')\n",
    "met2_vl = pd.read_pickle('kaggle/prepo_val_met2_bIDbyM_means.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kaggle/prepo_train_met2_tr_means_by_bid_and_m.pkl', 'wb') as f_out:\n",
    "    pickle.dump(mt_2tr_means_by_bid_and_m, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [x for x in list(met2_tr) if x not in ['timestamp', 'meter_reading']]\n",
    "y = 'meter_reading'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "met2_tr_x = met2_tr[xs]\n",
    "met2_tr_y = met2_tr[y]\n",
    "met2_vl_x = met2_vl[xs]\n",
    "met2_vl_y = met2_vl[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Ric/.local/lib/python3.5/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 40 rounds\n",
      "[20]\ttraining's rmse: 125887\tvalid_1's rmse: 305748\n",
      "[40]\ttraining's rmse: 71291.8\tvalid_1's rmse: 277235\n",
      "[60]\ttraining's rmse: 56917.8\tvalid_1's rmse: 271659\n",
      "[80]\ttraining's rmse: 49772.7\tvalid_1's rmse: 268601\n",
      "[100]\ttraining's rmse: 44980.6\tvalid_1's rmse: 267856\n",
      "[120]\ttraining's rmse: 41184.2\tvalid_1's rmse: 268652\n",
      "[140]\ttraining's rmse: 38212.3\tvalid_1's rmse: 269253\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's rmse: 44561.6\tvalid_1's rmse: 267463\n"
     ]
    }
   ],
   "source": [
    "mt2_lgb_train = lgb.Dataset(met2_tr_x, met2_tr_y)\n",
    "mt2_lgb_eval = lgb.Dataset(met2_vl_x, met2_vl_y)\n",
    "mt2_gbm_regress = lgb.train(lgb_reg_params, mt2_lgb_train, num_boost_round=2000, valid_sets=(mt2_lgb_train, mt2_lgb_eval),verbose_eval = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Ric/TSM/tsm/eval_metrics.py:5: RuntimeWarning: invalid value encountered in log\n",
      "  return np.sqrt(np.sum(np.power(np.log(predicted + 1) - np.log(actual + 1), 2)) / len(actual))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NRMLSE: 1.830378535525465\n",
      "Validation NRMLSE: 1.9614942522066001\n"
     ]
    }
   ],
   "source": [
    "lgbm_tr_hat = (gbm_regress.predict(met2_tr_x, num_iteration=gbm_regress.best_iteration))\n",
    "print('Training NRMLSE:', root_mean_squared_log_error(lgbm_tr_hat, met2_tr_y))\n",
    "\n",
    "lgbm_vl_hat = (gbm_regress.predict(met2_vl_x, num_iteration=gbm_regress.best_iteration))\n",
    "print('Validation NRMLSE:', root_mean_squared_log_error(lgbm_vl_hat, met2_vl_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/mt2_gbm_regress.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mt2_gbm_regress, 'models/mt2_gbm_regress.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                          Type              Data/Info\n",
      "-------------------------------------------------------------\n",
      "SEED                              int               0\n",
      "compress_memory_usage             function          <function compress_memory<...>_usage at 0x7f4a8449a1e0>\n",
      "compute_and_add_mean_by_a_and_b   function          <function compute_and_add<...>_and_b at 0x7f4a66aab1e0>\n",
      "f_out                             BufferedWriter    <_io.BufferedWriter name=<...>_means_by_bid_and_m.pkl'>\n",
      "gbm_regress                       Booster           <lightgbm.basic.Booster object at 0x7f4a669e5ac8>\n",
      "lgb                               module            <module 'lightgbm' from '<...>es/lightgbm/__init__.py'>\n",
      "lgb_eval                          Dataset           <lightgbm.basic.Dataset object at 0x7f4a669e5f28>\n",
      "lgb_reg_params                    dict              n=15\n",
      "lgb_train                         Dataset           <lightgbm.basic.Dataset object at 0x7f4a669e5b38>\n",
      "lgbm_tr_hat                       ndarray           2387956: 2387956 elems, type `float64`, 19103648 bytes (18.218658447265625 Mb)\n",
      "lgbm_vl_hat                       ndarray           320757: 320757 elems, type `float64`, 2566056 bytes (2.4471817016601562 Mb)\n",
      "met1_v2                           DataFrame                 building_id      <...>320757 rows x 59 columns]\n",
      "met2_tr                           DataFrame                  building_id  met<...>387956 rows x 58 columns]\n",
      "met2_tr_x                         DataFrame                  building_id  sit<...>387956 rows x 57 columns]\n",
      "met2_tr_y                         Series            0             0.000000\\n1<...>: 2387956, dtype: float32\n",
      "met2_vl                           DataFrame                 building_id  mete<...>320757 rows x 58 columns]\n",
      "met2_vl_x                         DataFrame                 building_id  site<...>320757 rows x 57 columns]\n",
      "met2_vl_y                         Series            0            0.000000\\n1 <...>h: 320757, dtype: float32\n",
      "met3_tr                           DataFrame                   building_id    <...>118728 rows x 47 columns]\n",
      "met3_vl                           DataFrame                   building_id    <...>145309 rows x 47 columns]\n",
      "mt_2tr_means_by_bid_and_m         dict              n=324\n",
      "only_add_mean_by_a_and_b          function          <function only_add_mean_b<...>_and_b at 0x7f4a66aab268>\n",
      "pd                                module            <module 'pandas' from '/u<...>ages/pandas/__init__.py'>\n",
      "pickle                            module            <module 'pickle' from '/u<...>lib/python3.5/pickle.py'>\n",
      "root_mean_squared_log_error       function          <function root_mean_squar<...>_error at 0x7f4a63dfad08>\n",
      "xs                                list              n=57\n",
      "y                                 str               meter_reading\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "del xs, y, mt_2tr_means_by_bid_and_m, met1_v2, met2_tr, met2_tr_x, met2_tr_y, met2_vl, met2_vl_x, met2_vl_y, lgb_train, lgbm_tr_hat, lgb_eval, lgbm_vl_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "met3_tr = pd.read_pickle('kaggle/prepo_train_met3.pkl')\n",
    "met3_vl = pd.read_pickle('kaggle/prepo_val_met3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e83049e745478c924dae5cbf92b3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1118728), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "met3_tr, mt_3tr_means_by_bid_and_m = compute_and_add_mean_by_a_and_b(met3_tr, mean_of='meter_reading', a='building_id', b='dt_m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e927f62b3a9f4b5b8261120930f1fb52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=145309), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "met3_vl = only_add_mean_by_a_and_b(met3_vl, mean_of='meter_reading', a='building_id', b='dt_m', means_by_a_and_b=mt_3tr_means_by_bid_and_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "met3_tr = met3_tr.drop('timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f8f646cfc848aab2a71613c37dd802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='DataFrame: compress_memory_usage', max=58, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage pre-compression was 362.7468566894531\n",
      "Memory usage after-compression was 204.8453369140625\n",
      "This is  56.4706028836606% of the initial size\n"
     ]
    }
   ],
   "source": [
    "met3_tr, _ = compress_memory_usage(met3_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "met3_vl = met3_vl.drop('timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281b4fc2f33a4825a3060520a3a5a817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='DataFrame: compress_memory_usage', max=58, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage pre-compression was 47.116458892822266\n",
      "Memory usage after-compression was 26.60699462890625\n",
      "This is  56.47070101220949% of the initial size\n"
     ]
    }
   ],
   "source": [
    "met3_vl, _ = compress_memory_usage(met3_vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "met3_tr = pd.read_pickle('kaggle/prepo_train_met3_bIDbyM_means.pkl')\n",
    "met3_vl = pd.read_pickle('kaggle/prepo_val_met3_bIDbyM_means.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kaggle/prepo_train_met3_tr_means_by_bid_and_m.pkl', 'wb') as f_out:\n",
    "    pickle.dump(mt_3tr_means_by_bid_and_m, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [x for x in list(met3_tr) if x not in ['timestamp', 'meter_reading']]\n",
    "y = 'meter_reading'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "met3_tr_x = met3_tr[xs]\n",
    "met3_tr_y = met3_tr[y]\n",
    "met3_vl_x = met3_vl[xs]\n",
    "met3_vl_y = met3_vl[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Ric/.local/lib/python3.5/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 40 rounds\n",
      "[20]\ttraining's rmse: 1355.6\tvalid_1's rmse: 1789.37\n",
      "[40]\ttraining's rmse: 1089.65\tvalid_1's rmse: 1677.05\n",
      "[60]\ttraining's rmse: 954.936\tvalid_1's rmse: 1658.86\n",
      "[80]\ttraining's rmse: 858.759\tvalid_1's rmse: 1665.79\n",
      "[100]\ttraining's rmse: 786.847\tvalid_1's rmse: 1667.93\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's rmse: 933.405\tvalid_1's rmse: 1654.98\n"
     ]
    }
   ],
   "source": [
    "mt3_lgb_train = lgb.Dataset(met3_tr_x, met3_tr_y)\n",
    "mt3_lgb_eval = lgb.Dataset(met3_vl_x, met3_vl_y)\n",
    "mt3_gbm_regress = lgb.train(lgb_reg_params, mt3_lgb_train, num_boost_round=2000, valid_sets=(mt3_lgb_train, mt3_lgb_eval),verbose_eval = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Ric/TSM/tsm/eval_metrics.py:5: RuntimeWarning: invalid value encountered in log\n",
      "  return np.sqrt(np.sum(np.power(np.log(predicted + 1) - np.log(actual + 1), 2)) / len(actual))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NRMLSE: 1.9423154769341195\n",
      "Validation NRMLSE: 2.1001962268893863\n"
     ]
    }
   ],
   "source": [
    "lgbm_tr_hat = (gbm_regress.predict(met3_tr_x, num_iteration=gbm_regress.best_iteration))\n",
    "print('Training NRMLSE:', root_mean_squared_log_error(lgbm_tr_hat, met3_tr_y))\n",
    "\n",
    "lgbm_vl_hat = (gbm_regress.predict(met3_vl_x, num_iteration=gbm_regress.best_iteration))\n",
    "print('Validation NRMLSE:', root_mean_squared_log_error(lgbm_vl_hat, met3_vl_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/mt3_gbm_regress.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mt3_gbm_regress, 'models/mt3_gbm_regress.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing overall baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_T0 = 10661397\n",
    "len_V0 = 1399513\n",
    "acc_T0 = 0.6020488382795164\n",
    "acc_V0 = 0.6820828571711314\n",
    "len_T1 = 3702435\n",
    "len_V1 = 480005\n",
    "acc_T1 = 1.5414553172411622\n",
    "acc_V1 = 1.7537242860741826\n",
    "len_T2 = 2387956\n",
    "len_V2 = 320757\n",
    "acc_T2 = 1.830378535525465\n",
    "acc_V2 = 1.9614942522066001\n",
    "len_T3 = 1118728\n",
    "len_V3 = 145309\n",
    "acc_T3 = 1.9423154769341195\n",
    "acc_V3 = 2.1001962268893863"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_T = len_T0 + len_T1 + len_T2 + len_T3\n",
    "len_V = len_V0 + len_V1 + len_V2 + len_V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_T = acc_T0 * (len_T0 / len_T) + acc_T1 * (len_T1 / len_T) + acc_T2 * (len_T2 / len_T) + acc_T3 * (len_T3 / len_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_V = acc_V0 * (len_V0 / len_V) + acc_V1 * (len_V1 / len_V) + acc_V2 * (len_V2 / len_V) + acc_V3 * (len_V3 / len_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0447155477119576, 1.1641964973385228)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_T, acc_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = len_T + len_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0585783898896715"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_T * len_T / L + acc_V * len_V / L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
